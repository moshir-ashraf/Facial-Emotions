{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center; font-weight:bold'>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "except OSError:\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center; font-weight:bold'>Downloading and Unpacking Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadData(path='./Dataset', name=\"fatihkgg/affectnet-yolo-format\"):\n",
    "    api = KaggleApi()\n",
    "    if not os.path.exists('./Dataset'): os.makedirs(path)\n",
    "    api.dataset_download_files(name, path=path, unzip=True)\n",
    "    print(\"Dataset downloaded successfully\")\n",
    "    \n",
    "# downloadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center; font-weight:bold'>Global Variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_BATCH_SIZE = 500\n",
    "CLASS_NAMES = [\n",
    "    \"Anger\",\n",
    "    \"Contempt\",\n",
    "    \"Disgust\",\n",
    "    \"Fear\",\n",
    "    \"Happy\",\n",
    "    \"Neutral\",\n",
    "    \"Sad\",\n",
    "    \"Surprise\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center; font-weight:bold'>Preparing Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(type):\n",
    "    imageDir = f\"Dataset/YOLO_format/{type}/images\"\n",
    "    labelDir = f\"Dataset/YOLO_format/{type}/labels\"\n",
    "\n",
    "    croppedImages = []\n",
    "    classNames = []\n",
    "\n",
    "    outputDir = f'Cropped Images/{type}'\n",
    "    if not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "\n",
    "    for className in CLASS_NAMES:\n",
    "        classDir = os.path.join(outputDir, className)\n",
    "        if not os.path.exists(classDir):\n",
    "            os.makedirs(classDir)\n",
    "\n",
    "    for imageFile in os.listdir(imageDir):\n",
    "        if not (imageFile.endswith(\".jpg\") or imageFile.endswith(\".png\")):\n",
    "            continue\n",
    "\n",
    "        imagePath = os.path.join(imageDir, imageFile)\n",
    "        labelFile = imageFile.replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "        labelPath = os.path.join(labelDir, labelFile)\n",
    "\n",
    "        if not os.path.exists(labelPath):\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(imagePath)\n",
    "        if image is None:\n",
    "            print(f\"Warning: Unable to read image {imagePath}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        height, width = image.shape[0:2]\n",
    "\n",
    "        with open(labelPath, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                try:\n",
    "                    data = line.strip().split()\n",
    "                    classId = int(data[0])  \n",
    "                    xCenter, yCenter, boxWidth, boxHeight = map(float, data[1:])\n",
    "\n",
    "                    xMin = int((xCenter - boxWidth / 2) * width)\n",
    "                    yMin = int((yCenter - boxHeight / 2) * height)\n",
    "                    xMax = int((xCenter + boxWidth / 2) * width)\n",
    "                    yMax = int((yCenter + boxHeight / 2) * height)\n",
    "\n",
    "                    xMin, yMin = max(0, xMin), max(0, yMin)\n",
    "                    xMax, yMax = min(width, xMax), min(height, yMax)\n",
    "\n",
    "                    croppedFace = image[yMin:yMax, xMin:xMax]\n",
    "\n",
    "                    if croppedFace.size == 0:\n",
    "                        continue\n",
    "\n",
    "                    croppedFace = cv2.resize(croppedFace, (416, 416))\n",
    "                    croppedFace = (croppedFace / 255.0).astype(\"float32\")\n",
    "\n",
    "                    croppedImages.append(croppedFace)\n",
    "                    classNames.append(CLASS_NAMES[classId])  \n",
    "\n",
    "                    classDir = os.path.join(outputDir, CLASS_NAMES[classId])\n",
    "                    fileName = f\"{imageFile.split('.')[0]}_{len(croppedImages)}.{imageFile.split('.')[1]}\"\n",
    "                    savePath = os.path.join(classDir, fileName)\n",
    "\n",
    "                    cv2.imwrite(savePath, croppedFace * 255.0)  \n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line '{line}' in {labelPath}: {e}\")\n",
    "\n",
    "        if len(croppedImages) >= LOAD_BATCH_SIZE:\n",
    "            df = pd.DataFrame({\"x\": croppedImages, \"y\": classNames})\n",
    "            yield df\n",
    "            croppedImages, classNames = [], []\n",
    "\n",
    "    if croppedImages:\n",
    "        df = pd.DataFrame({\"x\": croppedImages, \"y\": classNames})\n",
    "        yield df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t\t\t     Loading Data:\n",
      "\n",
      "********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Training Data: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Training Data: 35it [12:36, 21.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 17101 images, 17101 labels\n",
      "Training Data is Successfully Saved\n",
      "\n",
      "********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Validation Data: 11it [03:34, 19.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 5406 images, 5406 labels\n",
      "Validation Data is Successfully Saved\n",
      "\n",
      "********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Testing Data: 6it [01:50, 18.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 2755 images, 2755 labels\n",
      "Testing Data is Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\t\\t\\t\\t     Loading Data:\")\n",
    "print(f\"\\n********************************************************************************************\\n\")\n",
    "\n",
    "xTrain, yTrain = [], []\n",
    "try:\n",
    "    for i, batch in enumerate(tqdm(prepareData(\"train\"), desc=\"Loading Training Data\")):\n",
    "        xTrain.extend(batch[\"x\"].tolist())\n",
    "        yTrain.extend(batch[\"y\"].tolist())\n",
    "        \n",
    "    print(f\"Training: {len(xTrain)} images, {len(yTrain)} labels\")\n",
    "    print(\"Training Data is Successfully Saved\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error Loading Training Data: {e}\")\n",
    "\n",
    "time.sleep(1)\n",
    "try:\n",
    "    del xTrain, yTrain\n",
    "except Exception as e:\n",
    "    print(f\"Error Deleting Training Data: {e}\")\n",
    "        \n",
    "print(f\"\\n********************************************************************************************\\n\")\n",
    "gc.collect()\n",
    "\n",
    "xVal, yVal = [], []\n",
    "try:\n",
    "    for i, batch in enumerate(tqdm(prepareData(\"valid\"), desc=\"Loading Validation Data\")):\n",
    "        xVal.extend(batch[\"x\"].tolist())\n",
    "        yVal.extend(batch[\"y\"].tolist())\n",
    "        \n",
    "    print(f\"Validation: {len(xVal)} images, {len(yVal)} labels\")\n",
    "    print(f\"Validation Data is Successfully Saved\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error Loading Validation Data: {e}\") \n",
    "\n",
    "time.sleep(1)\n",
    "try:\n",
    "    del xVal, yVal\n",
    "except Exception as e:\n",
    "    print(f\"Error Deleting Validation Data: {e}\")\n",
    "        \n",
    "print(f\"\\n********************************************************************************************\\n\")\n",
    "gc.collect()\n",
    "\n",
    "xTest, yTest = [], []\n",
    "try:\n",
    "    for i, batch in enumerate(tqdm(prepareData(\"test\"), desc=\"Loading Testing Data\")):\n",
    "        xTest.extend(batch[\"x\"].tolist())\n",
    "        yTest.extend(batch[\"y\"].tolist())\n",
    "        \n",
    "    print(f\"Testing: {len(xTest)} images, {len(yTest)} labels\")\n",
    "    print(\"Testing Data is Successfully Saved\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error Loading Testing Data: {e}\")   \n",
    "        \n",
    "time.sleep(1)\n",
    "try:\n",
    "    del xTest, yTest\n",
    "except Exception as e:\n",
    "    print(f\"Error Deleting Testing Data: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
